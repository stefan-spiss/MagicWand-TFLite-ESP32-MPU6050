{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BtkMGSYQOTQ"
      },
      "source": [
        "# Train a gesture recognition model for microcontroller (ESP32) use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaFfr7DHRmGF"
      },
      "source": [
        "This notebook demonstrates how to train a 20kb gesture recognition model for [TensorFlow Lite for Microcontrollers](https://tensorflow.org/lite/microcontrollers/overview). It will produce the same model used in the [magic_wand_esp32_mpu6050](https://github.com/stefan/MagicWand-TFLite-ESP32-MPU6050/blob/new-data/magic_wand_esp32_mpu6050) application.\n",
        "\n",
        "The model is designed to be used with [Google Colaboratory](https://colab.research.google.com).\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/stefan-spiss/MagicWand-TFLite-ESP32-MPU6050/blob/new-data/train/train_magic_wand_model.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/stefan-spiss/MagicWand-TFLite-ESP32-MPU6050/blob/new-data/train/train_magic_wand_model.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXgS6rxyT7Qk"
      },
      "source": [
        "Training is much faster using GPU acceleration. Before you proceed, ensure you are using a GPU runtime by going to **Runtime -> Change runtime type** and selecting **GPU**. Training will take around 5 minutes on a GPU runtime."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LG6ErX5FRIaV"
      },
      "source": [
        "## Configure dependencies\n",
        "\n",
        "Run the following cell to ensure the correct version of TensorFlow is used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STNft9TrfoVh"
      },
      "source": [
        "We'll also clone the TensorFlow repository, which contains the training scripts, and copy them into our workspace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygkWw73dRNda"
      },
      "outputs": [],
      "source": [
        "# Clone the repository from GitHub\n",
        "!git clone --branch new-data --depth 1 -q https://github.com/stefan-spiss/MagicWand-TFLite-ESP32-MPU6050.git\n",
        "# Copy the training scripts into our workspace\n",
        "!cp -r MagicWand-TFLite-ESP32-MPU6050/train train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXI7R4RehFdU"
      },
      "source": [
        "## Prepare the data\n",
        "\n",
        "Next, we'll extract the data into the expected location within the training scripts' directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2Sg2AKzVr2L"
      },
      "outputs": [],
      "source": [
        "# Extract the data into the train directory\n",
        "!unzip  MagicWand-TFLite-ESP32-MPU6050/data/data.zip -d train\n",
        "#!tar xvzf data.tar.gz -C train 1>/dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNjukI1Sgl2C"
      },
      "source": [
        "We now inspect the data by plotting it."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The scripts must be run from within the train directory\n",
        "%cd train\n",
        "# Plot the data\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sb\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "from data_prepare import prepare_original_data\n",
        "from data_prepare import generate_negative_data\n",
        "\n",
        "LABEL_NAME = \"gesture\"\n",
        "DATA_NAME = \"accel_ms2_xyz\"\n",
        "folders = [\"wing\", \"ring\", \"slope\"]\n",
        "names = [\n",
        "    \"stefan\",\n",
        "    \"patrick\",\n",
        "    \"justin\",\n",
        "    \"yeongmi\"\n",
        "    \"arthur\",\n",
        "    \"kai\",\n",
        "    \"nico\",\n",
        "    \"filip\",\n",
        "    \"lukas\",\n",
        "    \"peter\",\n",
        "   \"Elekas\",\n",
        "    \"ruben\",\n",
        "    \"leo\",\n",
        "    \"alex\",\n",
        "    \"best\",\n",
        "    \"Sonja_Jasmin\",\n",
        "    \"fabian\",\n",
        "    \"andimeno\",\n",
        "    \"sm\",\n",
        "    \"sophia_23\",\n",
        "    \"LJ\",\n",
        "]\n",
        "\n",
        "data = []  # pylint: disable=redefined-outer-name\n",
        "for idx1, folder in enumerate(folders):\n",
        "  for idx2, name in enumerate(names):\n",
        "    prepare_original_data(folder, name, data,\n",
        "                          \"./data/%s/output_%s_%s.txt\" % (folder, folder, name))\n",
        "n_gestures = len(data)\n",
        "for idx, name in enumerate(names):\n",
        "  prepare_original_data(\"negative\", name, data,\n",
        "                        \"./data/negative/output_negative_%s.txt\" % (name))\n",
        "n_negative = len(data) - n_gestures\n",
        "folders.append(\"negative\")\n",
        "\n",
        "# if there are more than 10% more gesture samples per gesture as negative samples, generate additional negative\n",
        "# samples\n",
        "if n_gestures - n_negative * len(folders) > n_gestures/len(folders) * 0.1:\n",
        "  print(\"not enough negative samples available, creating random data samples\")\n",
        "  generate_negative_data(data, (math.ceil(n_gestures/len(folders)) - n_negative))\n",
        "n_negative = len(data) - n_gestures\n",
        "\n",
        "columns = [LABEL_NAME, \"name\", DATA_NAME]\n",
        "df = pd.DataFrame(data, columns=columns)\n",
        "  \n",
        "df_gesture_data = pd.DataFrame()\n",
        "for folder in folders:\n",
        "  for row in df.loc[df[LABEL_NAME] == folder].iterrows():\n",
        "    tmp_data = np.array(row[1][DATA_NAME])\n",
        "    df_tmp = pd.DataFrame({\n",
        "      \"name\": np.full(len(tmp_data), row[1][\"name\"]), \n",
        "      LABEL_NAME: np.full(len(tmp_data), folder),\n",
        "      \"t\": range(len(tmp_data)),\n",
        "      \"X\": tmp_data[:, 0],\n",
        "      \"Y\": tmp_data[:, 1],\n",
        "      \"Z\": tmp_data[:, 2]\n",
        "      })\n",
        "    df_gesture_data = pd.concat([df_gesture_data, df_tmp], ignore_index=True)\n",
        "\n",
        "# print(df_gesture_data)\n",
        "# sb.scatterplot(data = df_gesture_data, x = \"t\", y = \"X\", col)\n",
        "# for folder in folders:\n",
        "#   grid_X = sb.FacetGrid(df_gesture_data.loc[df_gesture_data[LABEL_NAME] == folder], col = \"name\", hue = LABEL_NAME, col_wrap=3)\n",
        "#   grid_X.map(sb.scatterplot, \"t\", \"X\")\n",
        "#   grid_X.add_legend()\n",
        "#   grid_Y = sb.FacetGrid(df_gesture_data.loc[df_gesture_data[LABEL_NAME] == folder], col = \"name\", hue = LABEL_NAME, col_wrap=3)\n",
        "#   grid_Y.map(sb.scatterplot, \"t\", \"Y\")\n",
        "#   grid_Y.add_legend()\n",
        "#   grid_Z = sb.FacetGrid(df_gesture_data.loc[df_gesture_data[LABEL_NAME] == folder], col = \"name\", hue = LABEL_NAME, col_wrap=3)\n",
        "#   grid_Z.map(sb.scatterplot, \"t\", \"Z\")\n",
        "#   grid_Z.add_legend()\n",
        "\n",
        "grid_X = sb.FacetGrid(df_gesture_data, col = LABEL_NAME, hue = \"name\", col_wrap=len(names))\n",
        "grid_X.map(sb.scatterplot, \"t\", \"X\")\n",
        "grid_X.add_legend()\n",
        "grid_Y = sb.FacetGrid(df_gesture_data, col = LABEL_NAME, hue = \"name\", col_wrap=len(names))\n",
        "grid_Y.map(sb.scatterplot, \"t\", \"Y\")\n",
        "grid_Y.add_legend()\n",
        "grid_Z = sb.FacetGrid(df_gesture_data, col = LABEL_NAME, hue = \"name\", col_wrap=len(names))\n",
        "grid_Z.map(sb.scatterplot, \"t\", \"Z\")\n",
        "grid_Z.add_legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ds-mz2e_QVeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll then run the scripts that split the data into training, validation, and test sets."
      ],
      "metadata": {
        "id": "PPayuEIVQZNe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBqSVpi6Vxss"
      },
      "outputs": [],
      "source": [
        "# Prepare the data\n",
        "!python data_prepare.py\n",
        "# Split the data by person\n",
        "#!python data_split_person.py\n",
        "# Split the data randomly since only one person available\n",
        "!python data_split.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-cmVbFvhTvy"
      },
      "source": [
        "## Load TensorBoard\n",
        "\n",
        "Now, we set up TensorBoard so that we can graph our accuracy and loss as training proceeds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCx6SN9NWRPw"
      },
      "outputs": [],
      "source": [
        "# Load TensorBoard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs/scalars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERC2Cr4PhaOl"
      },
      "source": [
        "## Begin training\n",
        "\n",
        "The following cell will begin the training process. Training will take around 5 minutes on a GPU runtime. You'll see the metrics in TensorBoard after a few epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXmQZgbuWQFO"
      },
      "outputs": [],
      "source": [
        "#!python train.py --model CNN --person true\n",
        "!python train.py --model CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gXbVzcXhvGD"
      },
      "source": [
        "## Create a C source file\n",
        "\n",
        "The `train.py` script writes a model, `model.tflite`, to the training scripts' directory.\n",
        "\n",
        "In the following cell, we convert this model into a C++ source file we can use with TensorFlow Lite for Microcontrollers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wgei4OGe3Nz"
      },
      "outputs": [],
      "source": [
        "# Install xxd if it is not available\n",
        "!apt-get -qq install xxd\n",
        "# Save the file as a C source file\n",
        "!xxd -i model.tflite > /content/model.cc\n",
        "!xxd -i model_best_val_accuracy.tflite > /content/model_best_val_accuracy.cc\n",
        "# Print the source file\n",
        "!cat /content/model_best_val_accuracy.cc"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Train a gesture recognition model for microcontroller (ESP32) use",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
